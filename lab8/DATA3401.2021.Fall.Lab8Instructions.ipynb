{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be274fa1",
   "metadata": {},
   "source": [
    "# <center>Lab 8 &ndash; DATA 3401 (Fall 2021)</center>\n",
    "\n",
    "## Lab Date: 11/12\n",
    "## Due Date 11/19 (before the beginning of lab)\n",
    "\n",
    "## Lab Description\n",
    "The purpose of this lab is for you to become more familiar with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11256997",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "1. Download the `wdbc.names` and `wdbc.data` text files in the Lab8 folder on GitHub. These come from the UCI repository https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "1. Use the native `open` command of Python to display the txt file `wdbs.names`\n",
    "1. Read the dataset from the `wdbc.data` file into a variable called `data` using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08bc211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "# Step 2\n",
      "########\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wdbc.names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108/4254451421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Showing WDBC names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'wdbc.names'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m    \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wdbc.names'"
     ]
    }
   ],
   "source": [
    "# Write your solutions here\n",
    "print(\"########\\n# Step 2\\n########\")\n",
    "# Showing WDBC names.\n",
    "filepath = 'wdbc.names'\n",
    "with open(filepath) as fp:\n",
    "   line = fp.readline()\n",
    "   cnt = 1\n",
    "   while line:\n",
    "       print(\"Line {}: {}\".format(cnt, line.strip()))\n",
    "       line = fp.readline()\n",
    "       cnt += 1\n",
    "\n",
    "print(\"\\n\\n########\\n# Step 3\\n########\")\n",
    "# Showing WDBC Data\n",
    "data = pd.read_csv(\"wdbc.data\") \n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6faff8",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "1. Display the data header using pandas\n",
    "1. Are there any columns that are not useful to analyzing this data?\n",
    "1. Decide what to do with the non-numerical data values, and modify your dataframe\n",
    "1. Extract the column of labels (Malignant or Benign, which should now be numerical values) from the dataframe and store it as a variable called `labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc835af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "# Step 1\n",
      "########\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108/238435881.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \"worst radius\", \"worst texture\", \"worst perimeter\", \"worst mean area\", \"worst smoothness\", \"worst compactness\", \"worst concavity\", ' worst concave points', 'worst symmetry', 'worst fractal dimension' ] \n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Write your solutions here\n",
    "# 1. Display the data header using pandas\n",
    "#########################################\n",
    "print(\"########\\n# Step 1\\n########\")\n",
    "\n",
    "headers = ['ID', \"Label\",\n",
    "            \"mean radius\", \"mean texture\", \"mean perimeter\", \"mean area\", \"mean smoothness\", \"mean compactness\", \"mean concavity\", \"mean concave points\", \"mean symmetry\", \"mean fractal dimension\",          \n",
    "            \"S.D radius\", \"S.D texture\", \"S.D perimeter\", \"S.D mean area\", \"S.D smoothness \", \"S.D compactness\", \"S.D concavity\", \"S.D concave points\", \"S.D symmetry\", \"S.D fractal dimension\",\n",
    "            \"worst radius\", \"worst texture\", \"worst perimeter\", \"worst mean area\", \"worst smoothness\", \"worst compactness\", \"worst concavity\", ' worst concave points', 'worst symmetry', 'worst fractal dimension' ] \n",
    "\n",
    "data.to_csv(\"new.csv\", header=headers, index=False)\n",
    "df = pd.read_csv(\"new.csv\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Are there any columns that are not useful to analyzing this data?\n",
    "#######################################################################\n",
    "## After researching the columns, there is only \"ID\" column which will not be required while analyzing the data. \n",
    "### Diagnosis, on the other hand, has a part in categorizing the data during the analysis.\n",
    "\n",
    "\n",
    "\n",
    "# 3. Decide what to do with the non-numerical data values, and modify your dataframe\n",
    "####################################################################################\n",
    "## Non-numerical values will be seperated from numerical values (excluding ID)\n",
    "### Main purpose is to categories them later.\n",
    "numerical_data = df.loc[:, ~df.columns.isin(['ID', \"Label\"])]\n",
    "# print(numerical_data)\n",
    "\n",
    "\n",
    "\n",
    "# 4. Extract the column of labels (Malignant or Benign, which should now be numerical values) from the dataframe \n",
    "#    and store it as a variable called labels\n",
    "################################################################################################################\n",
    "# Note, M = 1, B = 0\n",
    "labels = df[\"Label\"].factorize(['B','M'])[0]\n",
    "header_labels = pd.DataFrame(data=labels, columns=[\"Labels\"])\n",
    "# print(labels) # 568"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756a7f9",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "1. Plot the data in 5 different ways of your choosing (i.e., plot column 2 vs. column 3 or column 8 vs. column 1, etc.)\n",
    "    1. Your plot should be a scatter plot and should color the points according to whether the cancer is Malignant or Benign\n",
    "1. Now, create new variables `x` and `y` which are numpy arrays from your `data` and `labels` dataframes\n",
    "1. Using these, run the segment of code in the cell below which implements PCA on x (color code is green for benign and red for malignant)\n",
    "1. Compare this plot to the ones from step 1. Do you notice any difference? Do you think it would be easier to separate malignant and benign tumors based on one of these plots over the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5e191e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108/1641632097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "PCA3=PCA(n_components=2)\n",
    "XPCA = PCA3.fit_transform(X)\n",
    "plt.plot(XPCA[y==0,0],XPCA[y==0,1],'g.')\n",
    "plt.plot(XPCA[y==1,0],XPCA[y==1,1],'r.')\n",
    "plt.show()\n",
    "def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\n",
    "    # Scaling Data for testing\n",
    "    # data_1 = scale(data_1)\n",
    "    # data_2 = scale(data_2)\n",
    "\n",
    "    range =  np.random.randn(len(data_1))\n",
    "    plt.scatter(range, data_1, label=column_name_1, color='orange')\n",
    "    plt.scatter(range, data_2, label=column_name_2, color='green')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('X-Axis')\n",
    "    plt.ylabel('Y-Axis')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# 1. Plot the data in 5 different ways of your choosing\n",
    "#######################################################    \n",
    "print('########\\n# Step 1\\n########')\n",
    "comparison_plot_maker(numerical_data[\"mean radius\"], numerical_data[\"worst radius\"], \"Mean Radius vs Worst Radius\", \"Mean Radius\", \"Worst Radius\")\n",
    "comparison_plot_maker(numerical_data[\"S.D perimeter\"], numerical_data[\"worst perimeter\"], \"S.D Perimeter vs Worst Perimeter\", \"S.D Perimeter\", \"Worst Perimeter\")\n",
    "comparison_plot_maker(numerical_data[\"mean compactness\"], numerical_data[\"S.D compactness\"], \"Mean Compactness vs S.D Compactness\", \"Mean Compactness\", \"S.D Compactness\")\n",
    "comparison_plot_maker(numerical_data[\"mean smoothness\"], numerical_data[\"worst smoothness\"], \"Mean Smoothness vs Worst Smoothness\",\"Mean Smoothness\", \"Worst Smoothness\")\n",
    "comparison_plot_maker(numerical_data[\"S.D texture\"], numerical_data[\"mean texture\"], \"S.D texture vs Mean Texture\", \"S.D texture\", \"Mean Texture\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Variables x and y, numpy arrays from data and labels dataframes\n",
    "#################################################################\n",
    "# Scaling Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numerical_data)\n",
    "# print(scaled_data)\n",
    "\n",
    "# Assigning Variables\n",
    "X = scaler.transform(numerical_data)\n",
    "y = labels\n",
    "\n",
    "\n",
    "\n",
    "# 3. Implements PCA on X (green for benign; red for malignant)\n",
    "##############################################################\n",
    "print('########\\n# Step 2\\n########')\n",
    "\n",
    "# PCA\n",
    "PCA3=PCA(n_components=2)\n",
    "# print(X.shape)\n",
    "PCA3.fit(X)\n",
    "XPCA = PCA3.transform(X)\n",
    "# print(XPCA.shape)\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.title(\"PCA\")\n",
    "plt.xlabel('X-Axis')\n",
    "plt.ylabel('Y-Axis')\n",
    "\n",
    "plt.plot(XPCA[y==0,0],XPCA[y==0,1],'g.')\n",
    "plt.plot(XPCA[y==1,0],XPCA[y==1,1],'r.')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 4. Compare plot from step 1. \n",
    "## Do you notice any difference? \n",
    "## Would it be easier to separate malignant and benign tumors based on these plots over the others?\n",
    "#####################################################################################################\n",
    "\n",
    "# During the match of Step 1 and Step 2, it is harder to seperate malignant and benign in step 1 since \n",
    "## they are not a combined version like PCA, which makes the results more relieable and accurate. \n",
    "\n",
    "## On Another note, when taking scalers of data from step 1, it creates a combined data for column 1 and 2, \n",
    "### making it much more harder to seperate or realize its accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
